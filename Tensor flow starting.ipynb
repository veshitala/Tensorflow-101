{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is code to See your Visualization Within your Jupyter Notebokk\n",
    "### Code source is \n",
    "[click](https://github.com/machinelearning147/MachineLearning-YouTube/blob/master/src/Visualizing%20TensorFlow%20Graphs.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check Version of your Tensorflow\n",
    "display(\"Tensorflow version is\" + (tf.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd  ## To check you current Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building, Running, and Visualizing The tensorflow Model \n",
    "#### To access full Tutorial \n",
    "[click](https://app.pluralsight.com/library/courses/tensorflow-understanding-foundations/table-of-contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()      ## Initialize a graph \n",
    "with g.as_default():\n",
    "    \n",
    "    ### Let's define some constant\n",
    "\n",
    "    a = tf.constant(6 , name = 'constant_a')\n",
    "    b = tf.constant(3 , name = 'constant_b')\n",
    "    c = tf.constant(10 , name = 'constant_c')\n",
    "    d = tf.constant(5 , name = 'constant_d')\n",
    "\n",
    "    ## Create Some operations on them\n",
    "\n",
    "    mul = tf.multiply(a ,b  ,name='mul')\n",
    "    div = tf.div(c, d ,name='div')\n",
    "    addn = tf.add_n([mul ,div] , name='addn')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All these steps constructed A graph in tf  but it is not executed yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running and graph\n",
    "\n",
    "#### To get Actual values of computation we have to run the graph that is build \n",
    "#### In tensorflow first we built a graph then run it on multiple instances\n",
    "\n",
    "### We run tf.Session to make sesson object which will spervise whole process of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sess.run(addn))\n",
    "display(sess.run(mul))\n",
    "display(sess.run(div))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can call seeson to run on node and graph will run only till that node not beyond that node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter(\"logs\", g).close()  ## Open the graph\n",
    "show_graph(g) ## By running function and closing it simultainiously\n",
    "sess.close()\n",
    "### Close the session its good habit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()      ## Initialize a graph \n",
    "with g.as_default():\n",
    "    \n",
    "    ## Define Some constant\n",
    "    \n",
    "    a = tf.constant(6.5 , name = \"constant_a\")\n",
    "    b = tf.constant(3.4 , name = \"constant_b\")\n",
    "    c = tf.constant(3.0 , name = \"constant_c\")\n",
    "    d = tf.constant(100.2 , name = \"constant_d\")\n",
    "    \n",
    "    ##Do some calculations on them \n",
    "    \n",
    "    square = tf.square(a , name = 'square_a')\n",
    "    power = tf.pow(b,c,name = \"pow_b_c\")\n",
    "    sqrt = tf.sqrt(d,name = 'sqrt_d')\n",
    "    final_sum = tf.add_n([square , power , sqrt] , name = 'final_sum')\n",
    "    another_sum = tf.add_n([a,b,c,d,power] , name='another')\n",
    "    sess = tf.Session()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are many more mathe operation are there explore them in Tensorflow documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sess.run(square))\n",
    "display(sess.run(power))\n",
    "display(sess.run(sqrt))\n",
    "display(sess.run(final_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter(\"logs\", g).close()  ## Open the graph\n",
    "show_graph(g) ## By running function and closing it simultainiously\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank of tensor \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "Zerod =  tf.constant(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.rank(Zerod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneD = tf.constant(['How' , 'are'  , 'you'])\n",
    "sess.run(tf.rank(oneD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoD =  tf.constant([[1.0 , 2.3] , [1.5,2.9]])\n",
    "sess.run(tf.rank(twoD))\n",
    "\n",
    "### So we can extend to n-dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Explore some more mathematical operation on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "\n",
    "    x = tf.constant([100,200,300] , name='x')\n",
    "    y = tf.constant([1,2,3] , name='y')\n",
    "    sum_x = tf.reduce_sum(x , name ='sum_x')\n",
    "    prod_y  =tf.reduce_prod(y , name='prod_y')\n",
    "\n",
    "    final_div = tf.div(sum_x , prod_y , name = 'final_div')\n",
    "    final_mean = tf.reduce_mean([sum_x , prod_y] ,name =\"final_mean\")\n",
    "\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sess.run(x))\n",
    "display(sess.run(y))\n",
    "display(sess.run(sum_x))\n",
    "display(sess.run(prod_y))\n",
    "display(sess.run(final_div))\n",
    "display(sess.run(final_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter(\"logs\", g).close()  ## Open the graph\n",
    "show_graph(g) ## By running function and closing it simultainiously\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow is perfectly Compatible with NumPy\n",
    "\n",
    "#### Numpy Araays can be treated as tensors\n",
    "###  np.int32 == tf.int32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "zeroD = np.array(30 ,dtype=np.int32)\n",
    "oneD = np.array([5.6,2.2,3.2,9.0] , dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sess.run(tf.rank(zeroD)))\n",
    "display(sess.run(tf.shape(zeroD)))\n",
    "display(sess.run(tf.rank(oneD)))\n",
    "display(sess.run(tf.shape(oneD)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor are n-dimensional array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PlaceHolders In tensorflow\n",
    "\n",
    "##### Placeholders hold the place for a Tensor whose value will be available to it only at runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():   \n",
    "    \n",
    "    ## We defined some place holders \n",
    "\n",
    "    x = tf.placeholder(tf.int32 , shape=[3] , name = 'x')\n",
    "    y = tf.placeholder(tf.int32 , shape=[3] , name = 'y')\n",
    "\n",
    "    ## Done some math operation on them but there value is still unknown\n",
    "    sum_x = tf.reduce_sum(x , name ='sum_x')\n",
    "    prod_y  =tf.reduce_prod(y , name='prod_y')\n",
    "\n",
    "    final_div = tf.div(sum_x , prod_y , name = 'final_div')\n",
    "    final_mean = tf.reduce_mean([sum_x , prod_y] ,name =\"final_mean\")\n",
    "    sess =  tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.FileWriter(\"logs\", g).close()  ## Open the graph\n",
    "show_graph(g) ## By running function and closing it simultainiously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"sum(x):\" , sess.run(sum_x , feed_dict={x:[100,200,300]}))   ## we have to specify placeholder x\n",
    "\n",
    "display(\"prod(y):\" , sess.run(prod_y , feed_dict={y:[1,2,3]}))   ## we have to specify placeholder x\n",
    "\n",
    "display(\"sum(x)/prod(y):\" , sess.run(final_div , feed_dict={x:[10,20,30],y:[1,2,3]})) \n",
    "\n",
    "\n",
    "## we have to specify placeholder x and y both for this node beacuse this node requres both values to be executed\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Parameters  to fed into sess.run( )\n",
    "\n",
    "\n",
    "## Fetches and the Feed Dictionary\n",
    "\n",
    "#####  The fetches parameter always holds the node that you want to compute when you pass it to Session.run\n",
    " The fetches parameter indicates what it is that we want to compute, \n",
    "#####   And feed_dict is used to provide placeholders and variables to the sess.run\n",
    "\n",
    "\n",
    "#### sess.run(fetches , feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### y = Wx + b\n",
    "\n",
    "W = tf.constant([10,100] , name='const_w')\n",
    "\n",
    "## While instantiating these placeholders, we haven't specified a shape for the Tensor that it holds, \n",
    "### which means these placeholders can be Tensors of any shape.\n",
    "\n",
    "x = tf.placeholder(tf.int32 , name = 'x')\n",
    "b = tf.placeholder(tf.int32 , name = 'y')\n",
    "\n",
    "## operations\n",
    "\n",
    "Wx = tf.multiply(W , x , name=\"Wx\") ##every element of W will be multiplied by every element of x. \n",
    "                                    ##W and x have to be compatible Tensors, which means x has to be the same shape\n",
    "                                    ##and rank as W.\n",
    "y = tf.add(Wx ,b , name=\"y\")\n",
    "\n",
    "# y_ = x - b\n",
    "\n",
    "y_ = tf.subtract(x , b , name=\"y_\")\n",
    "\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(print(\"intermediate value :\" , sess.run(Wx , feed_dict={x:[3,33]})))\n",
    "display(print(\"Final value : Wx + b = \" , sess.run(y , feed_dict={x:[5 , 50] , b:[7 ,9]})))\n",
    "\n",
    "## Think of every Session.run as an independent calculation of the node that we've specified\n",
    "\n",
    "# you do not need to specify every value from scratch. You can also specify intermediate values\n",
    "## to run y let's specify Wx directly instead of specifying x\n",
    "\n",
    "display(print(\"for intermedite value of Wx := \" , sess.run(fetches=y , feed_dict={Wx:[100 , 1000] , b:[7 ,9]})))\n",
    "\n",
    "## You can mention fetches=node or its same by default\n",
    "#Allowing us to specify intermediate values is very useful for debugging.\n",
    "\n",
    "\n",
    "#We want to calculate the values of the nodes y as well as y_ in the same Session.run statement.\n",
    "#The fetches parameter should simply be an array which contains all the nodes that you want computed.\n",
    "\n",
    "\n",
    "display(print(\"Two results :[Wx + b , x-b] = \" ,sess.run(fetches=[y , y_] , feed_dict={x:[5,50] , b :[7,9]})))\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variables\n",
    "\n",
    "Variables in TensorFlow are constructs which allow you to change the value that is stored within them\n",
    ".Variables are mutable Tensor values that persist across multiple calls to Session.run. They hold their value 'til they're explicitly updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y =Wx + b\n",
    "\n",
    "W = tf.Variable([2.5,4.0] , tf.float32 , name=\"var_w\")\n",
    "\n",
    "x = tf.placeholder(tf.float32 ,name = 'x')\n",
    "\n",
    "b = tf.Variable([5.0,10.0] ,tf.float32 , name = \"var_b\")\n",
    "\n",
    "y = W*x + b\n",
    "\n",
    "## Initialize variables\n",
    "\n",
    "init = tf.global_variables_initializer()  ## this is alsp a computation node\n",
    "\n",
    "with tf.Session() as sess:    ## easy way to run multiple sessions\n",
    "    \n",
    "    sess.run(init)  ## otherwise error will be thrown\n",
    "    print(\"Final result : Wx + b  = \" ,(sess.run(y , feed_dict={x:[10 , 100]})))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = W*x\n",
    "\n",
    "s = W*x\n",
    "\n",
    "## Initialize only those value which you might need\n",
    "\n",
    "init = tf.variables_initializer([W])\n",
    "with tf.Session() as sess :   ## this will be a seperate session\n",
    "    \n",
    "    sess.run(init)\n",
    "    #print(\"this will throw error\" , (sess.run(y , feed_dict={x:[10 , 100]})))\n",
    "    print(\"Result : Wx =\" , sess.run(s,feed_dict={x:[10 , 100]}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see How variables got Updated during Computation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = tf.Variable(2)\n",
    "multiplier = tf.Variable(1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "result = number.assign(tf.multiply(number ,multiplier)) ## result is computation node\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(10):\n",
    "        print(\"Result : number*Multiplier\" , sess.run(result))\n",
    "        print(\"increment in multiplier ,updated value =\" , sess.run(multiplier.assign_add(1)))\n",
    "    print(\"see the updated values\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's See How to define multiple graph and view them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    with tf.Session as sess:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        run your code here\n",
    "        \n",
    "        \n",
    "        use assert statement to confirm\n",
    "        \n",
    "        \n",
    "        assert y.graph is g1\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    with tf.Session as sess:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        run your code here\n",
    "        \n",
    "        \n",
    "        use assert statement to confirm \n",
    "        \n",
    "        assert y.graph is g2\n",
    "        \n",
    "        \"\"\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We really need a way to organize things in TensorBoard, and this we can do using named scopes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named scopes let you logically group your computations and see how data flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        A = tf.constant([4], tf.int32 , name=\"A\")\n",
    "        B = tf.constant([5], tf.int32 , name=\"B\")\n",
    "        C = tf.constant([6], tf.int32 , name=\"C\")\n",
    "        \n",
    "        x = tf.placeholder(tf.int32  ,  name ='x')\n",
    "        \n",
    "        # Ax^2 + Bx+ C \n",
    "        \n",
    "        Ax2_1 = tf.multiply(A ,tf.pow(x,2) , name = \"Ax2_1\")\n",
    "        \n",
    "        Bx = tf.multiply(B ,x ,name = \"Bx\")\n",
    "        y1 = tf.add_n([Ax2_1 ,Bx ,C] , name = \"y1\")\n",
    "        \n",
    "        \n",
    "        # y = Ax^2+Bx^2\n",
    "        Ax2_2 = tf.multiply(A ,tf.pow(x,2) , name = \"Ax2_2\")\n",
    "        \n",
    "        Bx2 = tf.multiply(B ,x ,name = \"Bx2\")\n",
    "        y2 = tf.add_n([Ax2_1 ,Bx] , name = \"y2\")\n",
    "        \n",
    "        \n",
    "        y = y1+y2\n",
    "        \n",
    "        print(sess.run(y , feed_dict={x:[5]}))\n",
    "        \n",
    "        tf.summary.FileWriter(\"logs\", g).close()  ## Open the graph\n",
    "        show_graph(g)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here you can see that this graph became so much complicated and hard to visualize and see the flow of computation\n",
    "\n",
    "### Let's use name scope for same comptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three named scopes in this program. The first two named scopes feed into the third. Think of these named scopes as logical blocks of code that you might want to debug separately in TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()   \n",
    "with g.as_default():\n",
    "    A = tf.constant([4], tf.int32 , name=\"A\")\n",
    "    B = tf.constant([5], tf.int32 , name=\"B\")\n",
    "    C = tf.constant([6], tf.int32 , name=\"C\")\n",
    "\n",
    "    x = tf.placeholder(tf.int32  ,  name ='x')\n",
    "\n",
    "    # Ax^2 + Bx+ C \n",
    "    with tf.name_scope(\"Equation_1\"):\n",
    "        Ax2 = tf.multiply(A ,tf.pow(x,2) , name = \"Ax2\")\n",
    "\n",
    "        Bx = tf.multiply(B ,x ,name = \"Bx\")\n",
    "        y1 = tf.add_n([Ax2 ,Bx ,C] , name = \"y1\")\n",
    "\n",
    "\n",
    "    # y = Ax^2+Bx^2\n",
    "    with tf.name_scope(\"Equation_2\"):\n",
    "        Ax2 = tf.multiply(A ,tf.pow(x,2) , name = \"Ax2\")\n",
    "\n",
    "        Bx2 = tf.multiply(B ,x ,name = \"Bx2\")\n",
    "        y2 = tf.add_n([Ax2 ,Bx] , name = \"y2\")\n",
    "\n",
    "    with tf.name_scope(\"final_sum\"):\n",
    "        y = y1+y2\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        print(sess.run(y , feed_dict={x:[5]}))\n",
    "\n",
    "tf.summary.FileWriter(\"logs\", g).close()  ## Open the graph\n",
    "show_graph(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that Now our graph loks Much better and we can debug it easily because of different blocks of \n",
    "### code\n",
    "When you work on real machine learning programs with thousands of nodes, named scopes are an extremely handy tool to manage how your graph looks and to enable debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive  sessions in TensorFlow \n",
    "\n",
    "Interactive sessions allow you to work with a session in TensorFlow without holding a reference to the session instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession() #Storing it in the sess variable is not required if you're using interactive sessions\n",
    "A = tf.constant([4] , tf.int32 , name = \"A\")\n",
    "x = tf.placeholder(tf.int32 , name = 'x')\n",
    "\n",
    "y = A*x\n",
    "\n",
    "y.eval(feed_dict={x:[5]}) #We can simply run y.eval, and it'll automatically pick up the default interactive session\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running   y.eval    with an interactive session is the equivalent of    tf.get_default_session().run(y)\n",
    "\n",
    "nteractive sessions function exactly like regular sessions except that it makes writing TensorFlow code much less cumbersome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Overview: Linear Regression in TensorFlow\n",
    "\n",
    "\n",
    "This is a quick overview of linear regression implemented in TensorFlow for the sake of completeness. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the case of linear regression we can use single neuron to learn the pattern\n",
    "\n",
    "###        1.Linear regression \n",
    "\n",
    "###        2.Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we will set a baseline example of linear regression without using tensorflow then we will\n",
    "### implement same code in the tensorflow to learn different kind of parameter that can be tweaked to make our model more robust and generalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google = pd.read_csv(\"./Stocks Data/Google.csv\" , usecols=[0,5] ,names=['date' ,'Google'] ,header=0)\n",
    "sp500 = pd.read_csv(\"./Stocks Data/s&p 500.csv\" , usecols=[0,5],names=['date' ,'S&P 500'] ,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google.dropna(inplace=True)\n",
    "sp500.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google['sp500'] = sp500['S&P 500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google['date'] = pd.to_datetime(google['date'] ,format='%Y/%m/%d')\n",
    "google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google = google.sort_values(['date'] ,ascending=[True])\n",
    "google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let us change features into the percentage change of the closed price of stock\n",
    "\n",
    "returns = google[[key for key in dict(google.dtypes) if dict(google.dtypes)[key] in ['float64' ,'int64']]].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.dropna(inplace=True)\n",
    "returns.reset_index(inplace=True)\n",
    "\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = np.array(returns['Google'])\n",
    "ydata = np.array(returns['sp500'])   ### These are two numpy array on which we will perform our linear aregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets ,linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set up a linear model\n",
    "\n",
    "model  = linear_model.LinearRegression()\n",
    "\n",
    "model.fit(xdata.reshape(-1 ,1) , ydata.reshape(-1 ,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(model.coef_)\n",
    "display(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(xdata.reshape(-1 ,1) , ydata.reshape(-1 ,1))  ### Returns the coefficient of determination R^2 \n",
    "#of the prediction 1 is best and -1 is worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will implement same regression in tensorflow and compare the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()   ## To resety the graph to its default value\n",
    "\n",
    "W = tf.Variable(tf.zeros([1, 1]), name=\"W\")\n",
    "b = tf.Variable(tf.zeros([1]), name=\"b\")\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 1], name=\"x\")\n",
    "\n",
    "# x will have many rows and 1 column and W is a 1x1 matrix\n",
    "# Number of columns of x == number of rows for W\n",
    "Wx = tf.matmul(x, W)\n",
    "\n",
    "y = Wx + b\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 1], name=\"y_\")\n",
    "\n",
    "# Add summary ops to collect data\n",
    "W_hist = tf.summary.histogram(\"weights\", W)\n",
    "b_hist = tf.summary.histogram(\"biases\", b)\n",
    "y_hist = tf.summary.histogram(\"y\", y)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(y_ - y))\n",
    "\n",
    "cost_hist = tf.summary.histogram(\"cost\", cost)\n",
    "\n",
    "train_step_ftrl = tf.train.FtrlOptimizer(1).minimize(cost)\n",
    "\n",
    "\n",
    "# Total number of points for our x values\n",
    "dataset_size = len(xdata)\n",
    "\n",
    "def trainWithMultiplePointsPerEpoch(steps, train_step, batch_size):\n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('./linearregression_demo2', sess.graph)\n",
    "\n",
    "    for i in range(steps):\n",
    "      \n",
    "      \n",
    "\n",
    "      if dataset_size == batch_size:\n",
    "        batch_start_idx = 0\n",
    "      elif dataset_size < batch_size:\n",
    "        raise ValueError(\"dataset_size: %d, must be greater than batch_size: %d\" % (dataset_size, batch_size))\n",
    "      else:\n",
    "        \n",
    "        batch_start_idx = (i * batch_size) % (dataset_size)\n",
    "          \n",
    "        \n",
    "\n",
    "      batch_end_idx = batch_start_idx + batch_size\n",
    "\n",
    "      # Access the x and y values in batches\n",
    "      batch_xs = xdata[batch_start_idx : batch_end_idx]\n",
    "      batch_ys = ydata[batch_start_idx : batch_end_idx]\n",
    "\n",
    "      # Reshape the 1-D arrays as 2D feature vectors with many rows and 1 column\n",
    "      feed = { x: batch_xs.reshape(-1, 1), y_: batch_ys.reshape(-1, 1) }\n",
    "\n",
    "      sess.run(train_step, feed_dict=feed)\n",
    "\n",
    "      # Write out histogram summaries\n",
    "      \n",
    "\n",
    "      result = sess.run(merged_summary, feed_dict=feed)\n",
    "      writer.add_summary(result, i)\n",
    "\n",
    "      # Print result to screen for every 500 iterations\n",
    "      if (i + 1) % 500 == 0:\n",
    "        print(\"After %d iteration:\" % i)\n",
    "        print(\"W: %f\" % sess.run(W))\n",
    "        print(\"b: %f\" % sess.run(b))\n",
    "\n",
    "        print(\"cost: %f\" % sess.run(cost, feed_dict=feed))\n",
    "\n",
    "    writer.close()    \n",
    "\n",
    "trainWithMultiplePointsPerEpoch(5000, train_step_ftrl, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorBoard.start('./linearregression_demo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorBoard.close(pid) ## provide proper pid to close the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Images in Tensorflow\n",
    "\n",
    "Neural networks are a class of deep learning algorithms that perform really well in image recognition. This means that understanding how these images are represented in TensorFlow and working with these images become very important.\n",
    "\n",
    "As we learn more about applying machine learning techniques to recognize images, neural networks, specifically convolutional neural networks work very well for hard image recognition tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mp_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./Dendelion.JPG\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image  = mp_image.imread(filename)  ##The image variable holds the resultant image as a NumPy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"Image shape\" , image.shape)   ## This will give shape of the image\n",
    "display(\"Image array\" , image)  ## This will show the arrray of the each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= tf.Variable(image ,name=\"x\") #  x holds this image as a tensor.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    transpose = tf.transpose(x,perm=[1,0,2])  ## We are swapping 1 and 0\n",
    "    result = sess.run(transpose)\n",
    "    print(\"transposed image shape\" , result.shape)\n",
    "    plt.imshow(result)\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that dimensions are exchanged and image is trannsposed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is another easy way to do it in Tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= tf.Variable(image ,name=\"x\") #  x holds this image as a tensor.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    transpose = tf.image.transpose_image(x)  ## same work easily\n",
    "    result = sess.run(transpose)\n",
    "    print(\"transposed image shape\" , result.shape)\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tranforming the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_list = [\"./image/1.jpg\",\n",
    "                      \"./image/2.jpg\",\n",
    "                      \"./image/3.jpg\",\n",
    "                      \"./image/4.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a queue of file name usin name construct\n",
    "filename_queue = tf.train.string_input_producer(original_image_list) #takes in all the strings within our original_image_ \n",
    "                                                                      # list and creates a queue of these file names\n",
    "# rread entire image file\n",
    "image_reader = tf.WholeFileReader()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #Coordinate the loading of image file\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess , coord=coord)\n",
    "    image_list =[]\n",
    "    \n",
    "    for i in range(len(original_image_list)):\n",
    "        # Read whole file in the queue ,the first value returned in the tuple is file name\n",
    "        # which we are ignoring\n",
    "        \n",
    "        _ ,image_file = image_reader.read(filename_queue)\n",
    "        \n",
    "        \n",
    "        # Decode the image as JPEG format ,this will turn it into a tensor which we can use\n",
    "        # later in the training process\n",
    "        \n",
    "        image = tf.image.decode_jpeg(image_file)\n",
    "        \n",
    "        # get a tensor of resized image\n",
    "        image =  tf.image.resize_images(image ,[224,224])\n",
    "        \n",
    "        image.set_shape((224,224,3))\n",
    "        \n",
    "        image_array = sess.run(image)\n",
    "        print(image_array.shape)\n",
    "        \n",
    "        Image.fromarray(image_array.astype('uint8'),'RGB').show()\n",
    "        \n",
    "        image_list.append(tf.expand_dims(image_array , 0))\n",
    "        \n",
    "    # Finisg all the filename queue coordinator.\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    index = 0\n",
    "\n",
    "    ## Write image summary\n",
    "    summary_writer  = tf.summary.FileWriter('./m4_example2' , graph = sess.graph)\n",
    "    \n",
    "    for image_tensor in image_list:\n",
    "        summary_str = sess.run(tf.summary.image(\"image-\" +str(index) ,image_tensor))\n",
    "        summary_writer.add_summary(summary_str)\n",
    "        index+=1\n",
    "    \n",
    "    summary_writer.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "### This summary you can view in your Tensorboard visualization    \n",
    "    \n",
    "### Use tensorboard --logdir = \"m4_example2\"    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more operations on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a queue of file name usin name construct\n",
    "filename_queue = tf.train.string_input_producer(original_image_list) #takes in all the strings within our original_image_ \n",
    "                                                                      # list and creates a queue of these file names\n",
    "# rread entire image file\n",
    "image_reader = tf.WholeFileReader()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #Coordinate the loading of image file\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess , coord=coord)\n",
    "    image_list =[]\n",
    "    \n",
    "    for i in range(len(original_image_list)):\n",
    "        # Read whole file in the queue ,the first value returned in the tuple is file name\n",
    "        # which we are ignoring\n",
    "        \n",
    "        _ ,image_file = image_reader.read(filename_queue)\n",
    "        \n",
    "        \n",
    "        # Decode the image as JPEG format ,this will turn it into a tensor which we can use\n",
    "        # later in the training process\n",
    "        \n",
    "        image = tf.image.decode_jpeg(image_file)\n",
    "        \n",
    "        # get a tensor of resized image\n",
    "        image =  tf.image.resize_images(image ,[224,224])\n",
    "        \n",
    "        image.set_shape((224,224,3))\n",
    "        \n",
    "        image = tf.image.flip_up_down(image)\n",
    "        \n",
    "        \n",
    "        image  = tf.image.central_crop(image , central_fraction=0.5)\n",
    "        \n",
    "        image_array = sess.run(image)\n",
    "        print(image_array.shape)\n",
    "        \n",
    "        ## Convert numy array to a tensor\n",
    "        image_tensor = tf.stack(image_array)\n",
    "        print(image_tensor)\n",
    "        \n",
    "        image_list.append(image_tensor)\n",
    "        \n",
    "    # Finisg all the filename queue coordinator.\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "    \n",
    "    ## Convert all tensor in single tensor of 4 dimension\n",
    "    ## First dimension is the number of images in the list and rest is same\n",
    "    \n",
    "    images_tensor = tf.stack(image_list)\n",
    "    print(images_tensor)\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter('./m4_example3' , graph = sess.graph)\n",
    "    \n",
    "    \n",
    "    ## Write all the summary in single code \n",
    "    summary_str = sess.run(tf.summary.image(\"images\" , images_tensor ,max_outputs=4))\n",
    "    summary_writer.add_summary(summary_str)\n",
    "    \n",
    "    summary_writer.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "### This summary you can view in your Tensorboard visualization    \n",
    "    \n",
    "### Use tensorboard --logdir = \"m4_example3\"    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with MNIST  DataSet   Using KNN   algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist_data\", one_hot=True)\n",
    "training_digits , training_labels = mnist.train.next_batch(5000)\n",
    "\n",
    "test_digits , test_labels = mnist.train.next_batch(200)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input images\n",
    "training_digits_pl = tf.placeholder(\"float\" , [None ,784])\n",
    "\n",
    "\n",
    "\n",
    "test_digit_pl = tf.placeholder(\"float\" , [784])\n",
    "# nearest neighbours using L1 Distance\n",
    "\n",
    "l1_distance = tf.abs(tf.add(training_digits_pl , tf.negative(test_digit_pl)))\n",
    "\n",
    "distance = tf.reduce_sum(l1_distance , axis=1)\n",
    "\n",
    "\n",
    "pred = tf.arg_min(distance , 0)\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "#Initializa the variable\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session()  as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    ## loop over all the test digts\n",
    "    \n",
    "    for i in range(len(test_digits)):\n",
    "        nn_index = sess.run(pred , feed_dict={training_digits_pl:training_digits , test_digit_pl:test_digits[i ,:]})\n",
    "        \n",
    "        print(\"Test\" , i , \"Prediction : \" , np.argmax(training_labels[nn_index]) , \"True label:\" ,np.argmax(test_labels[i]))\n",
    "        \n",
    "        if np.argmax(training_labels[nn_index]) == np.argmax(test_labels[i]):\n",
    "            accuracy += 1/len(test_digits)\n",
    "            \n",
    "        print(\"done\")\n",
    "        print(\"accuracy: \" , accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Y0u can see our Accuracy is approximately 95%  which is pretty good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
